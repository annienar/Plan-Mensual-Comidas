# core/extraer_pdf.py
# ---------------------------------------------------
# ExtracciÃ³n robusta de texto desde PDFs (v1.4.9)
#  - Usa pdfplumber con tolerancias para respetar saltos
#  - Elimina menÃºs, footers y enlaces ruidosos
#  - Repara guiones de fin de lÃ­nea y une pÃ¡ginas
# ---------------------------------------------------

import re
import logging
import pdfplumber
from core.logger import configurar_logger, log_info, log_warning, log_error

# Suprime logs excesivos de pdfminer
logging.getLogger("pdfminer").setLevel(logging.ERROR)

# Inicializa logger del mÃ³dulo
logger = configurar_logger("extraer_pdf")


def extraer_texto_desde_pdf(path_pdf: str) -> str:
    """
    Devuelve el texto limpio del PDF en `path_pdf`, listo para parsear ingredientes.

    - Concatena todas las pÃ¡ginas con doble salto de lÃ­nea.
    - Elimina URLs, protocolos whatsapp://, javascript:, etc.
    - Suprime bloques de navegaciÃ³n/footers de la web.
    - Repara palabras rotas por guiÃ³n al final de lÃ­nea.
    - Loggea Ã©xito o error.
    """
    paginas: list[str] = []
    try:
        with pdfplumber.open(path_pdf) as pdf:
            for page in pdf.pages:
                # extrae texto conservando saltos de pÃ¡rrafo
                txt = page.extract_text(x_tolerance=1, y_tolerance=3) or ""
                paginas.append(txt.strip())
        bruto = "\n\n=== pÃ¡gina ===\n\n".join(paginas)
        log_info(f"ğŸ“„ Texto extraÃ­do correctamente de {path_pdf}")
    except Exception as e:
        log_error(f"âŒ Error al leer {path_pdf}: {e}")
        return ""

    # â”€â”€ Limpieza de enlaces y protocolos no deseados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    limpio = re.sub(r"https?://\S+|whatsapp://\S+|javascript:\S+", "", bruto)

    # â”€â”€ Suprime bloques de navegaciÃ³n/footers repetitivos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    patrones_ruido = [
        r"Â© COPYRIGHT.*?DERECHOS RESERVADOS",          # footer legal
        r"SÃ­guenos.*?Resumen de votos",                # secciÃ³n social
        r"PORTADA\s+RECETAS[\s\S]{0,400}?Bon Viveur",  # cabecera de web BonViveur
    ]
    for pat in patrones_ruido:
        limpio = re.sub(pat, "", limpio, flags=re.I | re.S)

    # â”€â”€ Normaliza espacios y tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    limpio = re.sub(r"[ \t]+", " ", limpio)

    # â”€â”€ Repara palabras partidas por guiÃ³n al final de lÃ­nea â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    limpio = re.sub(r"(\w+)-\n(\w+)", r"\1\2", limpio)

    # â”€â”€ Colapsa saltos de lÃ­nea mÃºltiples â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    limpio = re.sub(r"\n{3,}", "\n\n", limpio).strip()

    return limpio
